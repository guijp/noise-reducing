{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchaudio\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complex_to_tensor_2d(complex_tensor):\n",
    "    _, width, height = complex_tensor.shape\n",
    "    tensor_2d = torch.view_as_real(complex_tensor).reshape(2, width, height)\n",
    "    return tensor_2d\n",
    "\n",
    "def tensor_2d_to_complex(tensor_2d):\n",
    "    width, height, _ = tensor_2d.shape\n",
    "    complex_tensor = torch.view_as_real(tensor_2d).reshape(width, height, 2)\n",
    "    return complex_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NSynth(Dataset):\n",
    "    def __init__(self, annotations_path, audio_path, target_sr, number_of_samples, transform):\n",
    "        with open(annotations_path, 'r') as f:\n",
    "            self.annotations = json.load(f)\n",
    "        self.audio_path = audio_path\n",
    "        self.target_sr = target_sr\n",
    "        self.number_of_samples = number_of_samples\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        audio_sample_path = self._get_audio_sample_path(index)\n",
    "        signal, sr = torchaudio.load(audio_sample_path)\n",
    "        signal = self._resample(signal, sr)\n",
    "        signal = self._collapse_channels(signal)\n",
    "        signal = self._truncate_signal_size(signal, self.number_of_samples)\n",
    "        signal_transform = self.transform(signal)\n",
    "\n",
    "        white_noise = self._generate_white_noise(signal, pct=0.05)\n",
    "        noisy_signal = (signal + white_noise)\n",
    "        noisy_signal_transform = self.transform(noisy_signal)\n",
    "        return complex_to_tensor_2d(noisy_signal_transform), complex_to_tensor_2d(signal_transform)\n",
    "\n",
    "    def _resample(self, signal, sr):\n",
    "        if sr != self.target_sr:\n",
    "            resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=self.target_sr)\n",
    "            signal = resampler(signal)\n",
    "        return signal\n",
    "\n",
    "    def _get_audio_sample_path(self, index):\n",
    "        song_title = list(self.annotations.keys())[index] + '.wav'\n",
    "        path = os.path.join(self.audio_path, song_title)\n",
    "        return path\n",
    "\n",
    "    def _collapse_channels(self, signal):\n",
    "        if signal.shape[0]>1:\n",
    "            signal = torch.mean(signal, dim=0, keepdim=True)\n",
    "        return signal\n",
    "\n",
    "    def _generate_white_noise(self, signal, pct):\n",
    "        max_from_signal = signal.max().item()\n",
    "        white_noise = max_from_signal * pct * torch.rand_like(signal)\n",
    "        return white_noise\n",
    "    \n",
    "    def _truncate_signal_size(self, signal, sample_number):\n",
    "        if signal.shape[1] > sample_number:\n",
    "            signal = signal[:, :sample_number]\n",
    "        elif signal.shape[1] < sample_number:\n",
    "            pad_size = sample_number - signal.shape[1]\n",
    "            signal = torch.nn.functional.pad(signal, pad=(0, pad_size), value=0)\n",
    "        return signal\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AltConvTranspose2d(nn.Module):\n",
    "    def __init__(self, conv, output_size=None):\n",
    "        super().__init__()\n",
    "        self.conv = conv\n",
    "        self.output_size = output_size\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.conv(x, output_size=x.size())\n",
    "        return output\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=2, out_channels=16, kernel_size=3, padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=16, out_channels=8, kernel_size=3, padding='same'),\n",
    "            nn.ReLU()\n",
    "        ) \n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            AltConvTranspose2d(nn.ConvTranspose2d(in_channels=8, out_channels=8, kernel_size=3, padding=1)),\n",
    "            nn.ReLU(),\n",
    "            AltConvTranspose2d(nn.ConvTranspose2d(in_channels=8, out_channels=16, kernel_size=3, padding=1)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=16, out_channels=2, kernel_size=3, padding='same'),\n",
    "            nn.Sigmoid()\n",
    "        ) \n",
    "  \n",
    "    def forward(self, x): \n",
    "        encoded = self.encoder(x) \n",
    "        decoded = self.decoder(encoded) \n",
    "        return decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Autoencoder()\n",
    "\n",
    "TARGET_SAMPLE_RATE = 20000\n",
    "N_FFT = 1024\n",
    "WIN_LENGTH = 512\n",
    "\n",
    "spectogram = torchaudio.transforms.Spectrogram(n_fft=N_FFT, power=None)\n",
    "inverse_spec = torchaudio.transforms.InverseSpectrogram(n_fft=N_FFT)\n",
    "\n",
    "data = NSynth(  annotations_path = '../../Downloads/nsynth-test/examples.json', \n",
    "                audio_path = '../../Downloads/nsynth-test/audio', \n",
    "                target_sr = TARGET_SAMPLE_RATE,\n",
    "                number_of_samples=40000,\n",
    "                transform=spectogram)\n",
    "\n",
    "loader = DataLoader(data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, n_epochs, loss_fn, lr=3e-4):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    size = len(loader)\n",
    "    for epoch_i in range(n_epochs):\n",
    "        print(f'BATCH: [{epoch_i+1}/{n_epochs}]')\n",
    "        for i, (noisy_signal, clean_signal) in enumerate(loader):\n",
    "            # Forward Pass\n",
    "            clean_signal_prediction = model(noisy_signal)\n",
    "            loss = loss_fn(clean_signal_prediction, clean_signal)\n",
    "\n",
    "            # Backpropagate\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Display Results\n",
    "            print(f'    - [{i}/{size}]loss: {loss}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH: [1/1]\n",
      "    - [0/64]loss: 9.887795448303223\n",
      "    - [1/64]loss: 11.647099494934082\n",
      "    - [2/64]loss: 11.087203025817871\n",
      "    - [3/64]loss: 10.867298126220703\n",
      "    - [4/64]loss: 11.925589561462402\n",
      "    - [5/64]loss: 10.863648414611816\n",
      "    - [6/64]loss: 9.918437004089355\n",
      "    - [7/64]loss: 10.863984107971191\n",
      "    - [8/64]loss: 9.31159782409668\n",
      "    - [9/64]loss: 11.086263656616211\n",
      "    - [10/64]loss: 11.1966552734375\n",
      "    - [11/64]loss: 7.379568576812744\n",
      "    - [12/64]loss: 11.876327514648438\n",
      "    - [13/64]loss: 10.837469100952148\n",
      "    - [14/64]loss: 9.833489418029785\n",
      "    - [15/64]loss: 8.354236602783203\n",
      "    - [16/64]loss: 14.09255599975586\n",
      "    - [17/64]loss: 9.51359748840332\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-128-744ba1c51016>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-127-54177d5a9498>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loader, n_epochs, loss_fn, lr)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnoisy_signal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_signal\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0;31m# Forward Pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mclean_signal_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoisy_signal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_signal_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_signal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/venv/study/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-119-85937cdf20da>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mdecoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecoded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/venv/study/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/venv/study/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/venv/study/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-119-85937cdf20da>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/venv/study/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/venv/study/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, output_size)\u001b[0m\n\u001b[1;32m    923\u001b[0m         return F.conv_transpose2d(\n\u001b[1;32m    924\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m             output_padding, self.groups, self.dilation)\n\u001b[0m\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "train(autoencoder, loader, n_epochs=1, loss_fn=loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_signal_spec, clean_signal_spec = next(iter(loader))\n",
    "\n",
    "noisy_signal_spec_i = noisy_signal_spec[0]\n",
    "clean_signal_spec_i = clean_signal_spec[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 513, 79])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noisy_signal_spec_i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-140-ec5bff96bb0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnoisy_signal_spec_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "torch.tensor([noisy_signal_spec_i]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_signal_spec_pred = autoencoder(noisy_signal_spec_i.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 513, 79])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_signal_spec_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4870, 0.4552, 0.4103,  ..., 0.4659, 0.4584, 0.4604],\n",
       "         [0.5002, 0.4306, 0.4267,  ..., 0.4539, 0.4662, 0.4525],\n",
       "         [0.4741, 0.4467, 0.4466,  ..., 0.4526, 0.4590, 0.4579],\n",
       "         ...,\n",
       "         [0.4774, 0.4709, 0.4674,  ..., 0.4666, 0.4655, 0.4666],\n",
       "         [0.4773, 0.4714, 0.4675,  ..., 0.4673, 0.4659, 0.4681],\n",
       "         [0.4744, 0.4736, 0.4730,  ..., 0.4728, 0.4712, 0.4752]],\n",
       "\n",
       "        [[0.4725, 0.4839, 0.4772,  ..., 0.5000, 0.4998, 0.5167],\n",
       "         [0.4195, 0.4076, 0.4021,  ..., 0.4776, 0.4785, 0.4993],\n",
       "         [0.4355, 0.3906, 0.4117,  ..., 0.4699, 0.4877, 0.5006],\n",
       "         ...,\n",
       "         [0.4910, 0.4822, 0.4820,  ..., 0.4823, 0.4843, 0.4984],\n",
       "         [0.4925, 0.4829, 0.4816,  ..., 0.4821, 0.4830, 0.4967],\n",
       "         [0.5042, 0.4969, 0.4963,  ..., 0.4961, 0.4960, 0.5038]]],\n",
       "       grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_signal_spec_pred.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "view_as_real is only supported for complex tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-147-850a4befcac6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtensor_2d_to_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_signal_spec_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-144-0ca47624358c>\u001b[0m in \u001b[0;36mtensor_2d_to_complex\u001b[0;34m(tensor_2d)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtensor_2d_to_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_2d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_2d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mcomplex_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_as_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_2d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcomplex_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: view_as_real is only supported for complex tensors"
     ]
    }
   ],
   "source": [
    "tensor_2d_to_complex(clean_signal_spec_pred.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_signal_i = inverse_spec(noisy_signal_spec_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0109, 0.0023, 0.0356,  ..., 0.0205, 0.0169, 0.0301]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noisy_signal_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch, _, width, heigh = noisy_signal_spec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.8029e+01,  0.0000e+00,  1.3928e+01,  ...,  1.1009e+01,\n",
       "            0.0000e+00,  1.1007e+01],\n",
       "          [ 0.0000e+00,  1.0671e+01,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            1.0570e+01,  0.0000e+00],\n",
       "          [-1.1081e+01, -2.3842e-06, -6.8957e+00,  ..., -5.4371e+00,\n",
       "           -3.7014e-02, -5.5921e+00],\n",
       "          ...,\n",
       "          [-5.2303e-01, -6.9919e-07,  6.1342e-01,  ...,  1.1985e-01,\n",
       "           -6.8469e-02,  2.2392e-01],\n",
       "          [-3.6077e-02, -6.0674e-02,  5.3807e-02,  ..., -1.4203e-01,\n",
       "           -5.3823e-02,  2.3000e-02],\n",
       "          [ 3.1877e-01,  0.0000e+00, -2.6981e-01,  ..., -3.9399e-03,\n",
       "            5.5269e-02, -2.9821e-01]],\n",
       "\n",
       "         [[ 1.2707e-01, -6.5051e-02, -7.4519e-02,  ...,  1.8152e-01,\n",
       "           -3.9045e-02, -2.1917e-02],\n",
       "          [ 3.3153e-02, -4.6077e-07, -4.9430e-02,  ..., -2.1661e-01,\n",
       "           -3.5724e-02,  3.2197e-01],\n",
       "          [ 6.6999e-02,  2.7580e-01, -1.3612e-02,  ..., -1.7254e-01,\n",
       "            6.2216e-02,  1.4341e-01],\n",
       "          ...,\n",
       "          [-5.3069e-02, -7.6925e-02, -1.5868e-01,  ..., -9.7084e-02,\n",
       "            3.8286e-01,  2.1713e-02],\n",
       "          [ 4.0137e-01,  0.0000e+00,  4.5662e-03,  ...,  1.5273e-01,\n",
       "            0.0000e+00,  2.2614e-01],\n",
       "          [ 0.0000e+00,  2.2278e-01,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           -6.6294e-01,  0.0000e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 9.1220e+00,  0.0000e+00,  9.1659e+00,  ...,  9.6356e+00,\n",
       "            0.0000e+00,  9.0820e+00],\n",
       "          [ 0.0000e+00,  9.3230e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           -4.7861e+00,  0.0000e+00],\n",
       "          [-3.7972e+00, -7.1526e-07, -5.1007e+00,  ..., -4.1952e+00,\n",
       "            3.5955e-01, -4.7456e+00],\n",
       "          ...,\n",
       "          [ 1.0263e-02,  7.6659e-08, -1.1010e-01,  ...,  2.2529e-01,\n",
       "            2.0412e-01, -1.3139e-01],\n",
       "          [ 5.3417e-02, -1.3329e-01,  2.0641e-02,  ..., -2.6336e-02,\n",
       "           -3.7199e-02,  9.5931e-02],\n",
       "          [ 2.3475e-02,  0.0000e+00,  6.8856e-02,  ...,  4.8263e-02,\n",
       "           -1.0888e-01,  7.2284e-02]],\n",
       "\n",
       "         [[-3.7548e-02,  1.0332e-01, -2.6333e-02,  ...,  2.7535e-02,\n",
       "            3.6840e-02, -1.5152e-02],\n",
       "          [-1.8164e-01, -2.2136e-07,  5.9779e-02,  ..., -2.2527e-01,\n",
       "           -1.8794e-01, -3.5462e-02],\n",
       "          [ 1.6011e-01, -4.1965e-02,  1.0847e-01,  ...,  3.8962e-02,\n",
       "           -7.1424e-02, -1.2079e-01],\n",
       "          ...,\n",
       "          [ 8.3590e-04, -1.3747e-01, -5.3203e-03,  ...,  1.7858e-01,\n",
       "            1.9729e-01,  6.1933e-02],\n",
       "          [ 2.0224e-01,  0.0000e+00,  1.4379e-01,  ..., -3.0099e-02,\n",
       "            0.0000e+00,  1.3378e-01],\n",
       "          [ 0.0000e+00,  2.6158e-01,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           -2.6063e-01,  0.0000e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 6.9653e+00,  0.0000e+00,  6.6275e+00,  ...,  6.4714e+00,\n",
       "            0.0000e+00,  6.3910e+00],\n",
       "          [ 0.0000e+00,  6.4911e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            6.6353e+00,  0.0000e+00],\n",
       "          [-3.5262e+00, -3.5763e-07, -3.2916e+00,  ..., -3.2368e+00,\n",
       "           -1.3691e-01, -3.2125e+00],\n",
       "          ...,\n",
       "          [-1.2568e-01,  2.4796e-08,  1.1795e-01,  ...,  1.6805e-02,\n",
       "            7.5559e-02,  1.3024e-01],\n",
       "          [ 7.5199e-02,  4.3205e-02, -1.1261e-01,  ...,  1.9737e-01,\n",
       "            3.0287e-02, -1.3288e-01],\n",
       "          [ 2.0215e-01,  1.1921e-07,  6.1524e-02,  ..., -5.9011e-02,\n",
       "           -2.9613e-01,  1.9173e-02]],\n",
       "\n",
       "         [[-1.0547e-01, -2.5521e-02,  6.1915e-02,  ..., -1.5363e-01,\n",
       "           -2.5746e-02,  1.1390e-01],\n",
       "          [-8.4979e-03,  2.4796e-08, -3.3047e-02,  ...,  1.1570e-01,\n",
       "            2.3030e-01, -1.4528e-01],\n",
       "          [-2.3259e-02, -3.2415e-03,  5.7541e-02,  ...,  2.6075e-02,\n",
       "           -6.5447e-02, -9.4994e-02],\n",
       "          ...,\n",
       "          [-9.7190e-02, -1.2355e-02,  1.2583e-01,  ..., -1.7231e-01,\n",
       "            1.8156e-01, -3.7229e-03],\n",
       "          [ 5.4438e-02,  0.0000e+00, -1.9558e-01,  ...,  2.0963e-01,\n",
       "            0.0000e+00, -2.0515e-01],\n",
       "          [ 0.0000e+00,  1.7348e-02,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           -3.3348e-01,  0.0000e+00]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 8.6221e+00,  0.0000e+00,  1.0647e+01,  ...,  1.1032e+01,\n",
       "            0.0000e+00,  1.1131e+01],\n",
       "          [ 0.0000e+00,  1.0996e+01,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            1.1079e+01,  0.0000e+00],\n",
       "          [-3.6533e+00, -2.3842e-07, -5.2630e+00,  ..., -5.3189e+00,\n",
       "           -4.8275e-02, -5.5921e+00],\n",
       "          ...,\n",
       "          [ 4.0068e-01, -1.7229e-08,  1.6211e-02,  ...,  4.5197e-01,\n",
       "           -3.2831e-01, -1.3036e-01],\n",
       "          [-1.9230e-01, -5.5346e-02,  5.9268e-02,  ..., -2.7036e-01,\n",
       "            6.9832e-02, -1.2968e-01],\n",
       "          [-5.9218e-02,  2.3842e-07, -1.5195e-01,  ..., -4.3543e-01,\n",
       "            2.0726e-01,  1.8230e-01]],\n",
       "\n",
       "         [[ 2.9222e-01,  2.4400e-01, -2.5095e-02,  ...,  2.1840e-01,\n",
       "           -3.6985e-02,  2.3712e-02],\n",
       "          [-1.4754e-01, -1.7229e-08,  1.6735e-01,  ...,  3.0926e-01,\n",
       "            1.7243e-01,  5.0894e-03],\n",
       "          [-2.6195e-01, -3.4002e-01,  3.8753e-02,  ..., -2.0515e-01,\n",
       "            5.8100e-02,  1.0783e-01],\n",
       "          ...,\n",
       "          [ 1.5830e-01, -5.4750e-02, -3.0431e-02,  ..., -2.1402e-01,\n",
       "           -8.4734e-02,  1.2370e-01],\n",
       "          [-5.5374e-01,  0.0000e+00,  2.1104e-01,  ..., -2.9273e-02,\n",
       "            0.0000e+00,  1.3525e-01],\n",
       "          [ 0.0000e+00,  3.0335e-02,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            4.3869e-01,  0.0000e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 1.0242e+01,  0.0000e+00,  1.0270e+01,  ...,  1.0653e+01,\n",
       "            0.0000e+00,  1.1198e+01],\n",
       "          [ 0.0000e+00,  1.0823e+01,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            1.2933e+01,  0.0000e+00],\n",
       "          [-4.9686e+00, -2.3842e-07, -5.1026e+00,  ..., -5.2389e+00,\n",
       "            2.2421e-01, -5.7740e+00],\n",
       "          ...,\n",
       "          [-2.8336e-01, -2.2468e-08,  2.2060e-01,  ...,  2.1465e-01,\n",
       "            1.1344e-01, -3.4234e-01],\n",
       "          [-7.2150e-02,  3.6081e-02,  2.7076e-01,  ..., -8.0914e-02,\n",
       "           -7.8517e-02,  1.3632e-01],\n",
       "          [ 1.2753e-01,  0.0000e+00, -2.1226e-01,  ..., -9.7526e-02,\n",
       "           -7.5202e-03,  4.6918e-01]],\n",
       "\n",
       "         [[ 1.0665e-01,  3.9328e-02,  3.0537e-03,  ..., -6.1584e-02,\n",
       "            1.2235e-02, -5.7124e-02],\n",
       "          [ 6.2389e-02, -2.2468e-08,  2.1547e-01,  ...,  1.4786e-01,\n",
       "           -1.3541e-01, -3.6233e-01],\n",
       "          [-1.0287e-01, -7.8082e-02, -1.4038e-01,  ...,  6.7515e-02,\n",
       "            4.4710e-02,  6.6590e-02],\n",
       "          ...,\n",
       "          [ 1.6699e-02, -2.4447e-01,  1.7935e-01,  ..., -1.3402e-01,\n",
       "           -2.8665e-01, -1.4267e-01],\n",
       "          [ 1.0912e-01,  0.0000e+00,  5.9172e-02,  ..., -1.9192e-01,\n",
       "            0.0000e+00, -2.8198e-01],\n",
       "          [ 0.0000e+00,  2.5932e-01,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            2.6028e-01,  0.0000e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 2.2788e+01,  0.0000e+00,  3.1559e+01,  ...,  1.5049e+02,\n",
       "            0.0000e+00,  1.5124e+02],\n",
       "          [ 0.0000e+00,  1.5144e+02,  0.0000e+00,  ...,  0.0000e+00,\n",
       "            1.4132e+02,  0.0000e+00],\n",
       "          [-1.0249e+01, -9.5367e-07, -1.5890e+01,  ..., -7.5295e+01,\n",
       "            6.9382e-02, -7.5764e+01],\n",
       "          ...,\n",
       "          [ 2.4931e-02, -3.2379e-07,  1.5146e-01,  ..., -2.6388e-01,\n",
       "           -2.6386e-02,  2.4566e-02],\n",
       "          [ 6.8894e-02,  1.0859e-02, -1.0931e-01,  ...,  2.8183e-01,\n",
       "           -1.3087e-01,  5.1075e-02],\n",
       "          [ 1.0677e-01,  0.0000e+00, -1.3348e-01,  ...,  7.9571e-02,\n",
       "            7.5645e-03,  6.2664e-02]],\n",
       "\n",
       "         [[-1.5650e-01, -3.8384e-01,  4.0086e-01,  ..., -2.7220e-01,\n",
       "            3.2398e-02,  2.5931e-01],\n",
       "          [ 8.1300e-02, -8.5376e-08,  1.8870e-01,  ...,  1.1737e+00,\n",
       "           -6.3232e-01,  1.2357e+00],\n",
       "          [-3.6775e-01,  1.3078e+00, -1.9780e+00,  ...,  2.3321e-01,\n",
       "           -4.5718e-02, -2.2377e-01],\n",
       "          ...,\n",
       "          [-1.5999e-02,  6.8672e-02,  1.0009e-01,  ...,  1.6260e-01,\n",
       "            2.5791e-01,  3.5351e-02],\n",
       "          [-4.5895e-01,  0.0000e+00, -3.9472e-01,  ...,  3.6682e-02,\n",
       "            0.0000e+00,  3.0032e-01],\n",
       "          [ 0.0000e+00, -9.9396e-02,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           -4.3053e-01,  0.0000e+00]]]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch, _, width, heigh = noisy_signal_spec.shape\n",
    "torch.view_as_real(noisy_signal_spec).reshape(batch, 2, width, heigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.5 ('study')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a2282c59fc62e496575584c9dbb07c6d2b8e29762f5e38bc89c1826f2135d1f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
